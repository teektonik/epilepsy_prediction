{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f29273c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e73b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpilepsyDataset(Dataset):\n",
    "    def __init__(self, path_to_data: str, verbose: bool=True):\n",
    "        if os.path.exists(path_to_data) is False:\n",
    "            raise ValueError('There is no such path')\n",
    "            \n",
    "        self.path = path_to_data\n",
    "        self.folders_with_patients = os.listdir(self.path)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.patients_data = []\n",
    "        for patient in self.folders_with_patients:\n",
    "            self.patients_data.append(os.listdir(os.path.join(self.path + patient)))\n",
    "            \n",
    "        self._dataset_data = []\n",
    "        \n",
    "    def get_patients_data(self, patient: str) -> list[str]:\n",
    "        return os.listdir(os.path.join(self.path, patient))\n",
    "    \n",
    "    def get_patients_names(self) -> list[str]:\n",
    "        return os.listdir(self.path)\n",
    "    \n",
    "    def get_all_sensors_records_for_patient(self, patient: str) -> list[str]:\n",
    "        if patient not in self.get_patients_names():\n",
    "            raise ValueError('There is no such name')\n",
    "         \n",
    "        full_path_to_patient = os.path.join(self.path, patient) \n",
    "        \n",
    "        return [name for name in os.listdir(full_path_to_patient) \n",
    "                if os.path.isdir(os.path.join(full_path_to_patient, name)) \n",
    "                and name[0] != '.']\n",
    "    \n",
    "    def _get_sorted_segments(self, sensor_folder: str) -> list[list]:\n",
    "        \"\"\"\n",
    "        Get types of sensors from folder and sort its data by number of segment\n",
    "        \"\"\"\n",
    "        \n",
    "        delimiter = '_'\n",
    "        full_path = os.path.join(self.path, sensor_folder)\n",
    "        sensors_files_names = [file.split(delimiter) for file in os.listdir(full_path)]\n",
    "\n",
    "        cropped_sensors_files_names = [file[:-2] for file in sensors_files_names]\n",
    "        \n",
    "        index_of_parameters = 3\n",
    "        unique_parameters = set(file[index_of_parameters] for file in cropped_sensors_files_names)\n",
    "\n",
    "        return_data = []\n",
    "        for unique_item in unique_parameters:\n",
    "            data = [file for file in sensors_files_names if unique_item in file]\n",
    "            index_of_segments_number = 5\n",
    "            sorted_list = sorted(data, key=lambda x: int(x[index_of_segments_number].split('.')[0]))\n",
    "            return_data.append(['_'.join(file) for file in sorted_list])\n",
    "    \n",
    "        return return_data\n",
    "    \n",
    "    def _read_segment(self, path_to_segment: str):\n",
    "        return pd.read_parquet(path_to_segment)\n",
    "    \n",
    "    def _upsample(self, data: np.array, sample_rate: float, new_sample_rate: float, mode: str = 'bicubic'):\n",
    "        scale_factor = new_sample_rate / sample_rate\n",
    "        upsampler = nn.Upsample(scale_factor, mode)\n",
    "        return upsampler(data)\n",
    "    \n",
    "    def _create_stacked_items(self):\n",
    "        \"\"\"\n",
    "        Return path to segments sorted by its index\n",
    "        \"\"\"\n",
    "        self._dataset_data = []\n",
    "        for patient in self.folders_with_patients:\n",
    "            if self.verbose:\n",
    "                print('Patient: {}'.format(patient))\n",
    "                \n",
    "            sensors = dataset.get_all_sensors_records_for_patient(patient)\n",
    "            data = []\n",
    "            for sensor in sensors:\n",
    "                records = dataset._get_sorted_segments(os.path.join(patient, sensor))\n",
    "                \n",
    "                full_path_records = []\n",
    "                for sensor_record in records:\n",
    "                    full_path_records.append(list(map(lambda x: os.path.join(self.path, patient, sensor, x), sensor_record)))                                \n",
    "                    data.append(full_path_records)\n",
    "                    \n",
    "            self._dataset_data.append(data)        \n",
    "\n",
    "        return self._dataset_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d3213",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EpilepsyDataset('/workspace/data_seerpy/data_seerpy/data/')\n",
    "\n",
    "data = dataset._create_stacked_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865fb944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
