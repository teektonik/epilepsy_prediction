{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e375fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpilepsyDataset(Dataset):\n",
    "    def __init__(self, path_to_data: str, verbose: bool=True):\n",
    "        if os.path.exists(path_to_data) is False:\n",
    "            raise ValueError('There is no such path')\n",
    "            \n",
    "        self.path = path_to_data\n",
    "        self.folders_with_patients = os.listdir(self.path)\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.patients_data = []\n",
    "        for patient in self.folders_with_patients:\n",
    "            self.patients_data.append(os.listdir(os.path.join(self.path + patient)))\n",
    "            \n",
    "        self._sorted_data = self._get_sorted_data()\n",
    "        \n",
    "    def get_patients_data(self, patient: str) -> list[str]:\n",
    "        return os.listdir(os.path.join(self.path, patient))\n",
    "    \n",
    "    def get_patients_names(self) -> list[str]:\n",
    "        return os.listdir(self.path)\n",
    "    \n",
    "    def get_all_sensors_records_for_patient(self, patient: str) -> list[str]:\n",
    "        if patient not in self.get_patients_names():\n",
    "            raise ValueError('There is no such name')\n",
    "         \n",
    "        full_path_to_patient = os.path.join(self.path, patient) \n",
    "        \n",
    "        return [name for name in os.listdir(full_path_to_patient) \n",
    "                if os.path.isdir(os.path.join(full_path_to_patient, name)) \n",
    "                and name[0] != '.']\n",
    "    \n",
    "    def _get_sorted_segments(self, sensor_folder: str) -> list[list]:\n",
    "        \"\"\"\n",
    "        Get types of sensors from folder and sort its data by number of segment\n",
    "        \"\"\"\n",
    "        \n",
    "        delimiter = '_'\n",
    "        full_path = os.path.join(self.path, sensor_folder)\n",
    "        sensors_files_names = [file.split(delimiter) for file in os.listdir(full_path)]\n",
    "\n",
    "        cropped_sensors_files_names = [file[:-2] for file in sensors_files_names]\n",
    "        \n",
    "        index_of_parameters = 3\n",
    "        unique_parameters = set(file[index_of_parameters] for file in cropped_sensors_files_names)\n",
    "\n",
    "        return_data = []\n",
    "        for unique_item in unique_parameters:\n",
    "            data = [file for file in sensors_files_names if unique_item in file]\n",
    "            index_of_segments_number = 5\n",
    "            sorted_list = sorted(data, key=lambda x: int(x[index_of_segments_number].split('.')[0]))\n",
    "            return_data.append(['_'.join(file) for file in sorted_list])\n",
    "    \n",
    "        return return_data\n",
    "    \n",
    "    def _read_segment(self, path_to_segment: str):\n",
    "        return pd.read_parquet(path_to_segment)\n",
    "    \n",
    "    def _upsample(self, data: np.array, sample_rate: float, new_sample_rate: float, mode: str = 'bicubic'):\n",
    "        scale_factor = new_sample_rate / sample_rate\n",
    "        upsampler = nn.Upsample(scale_factor, mode)\n",
    "        return upsampler(data)\n",
    "    \n",
    "    def _get_sorted_data(self):\n",
    "        \"\"\"\n",
    "        Return path to segments sorted by its index\n",
    "        \"\"\"\n",
    "        self._dataset_data = []\n",
    "        print(self.folders_with_patients)\n",
    "        for patient in self.folders_with_patients:\n",
    "            if self.verbose:\n",
    "                print('Patient: {}'.format(patient))\n",
    "                \n",
    "            sensors = self.get_all_sensors_records_for_patient(patient)\n",
    "            data = []\n",
    "            for sensor in sensors:\n",
    "                records = self._get_sorted_segments(os.path.join(patient, sensor))\n",
    "                \n",
    "                full_path_records = []\n",
    "                for sensor_record in records:\n",
    "                    full_path_records.append(list(map(lambda x: os.path.join(self.path, patient, sensor, x), sensor_record)))                                \n",
    "                    data.append(full_path_records)\n",
    "                    \n",
    "            self._dataset_data.append(data)        \n",
    "\n",
    "        return self._dataset_data\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "    \n",
    "    def _get_fullconnected_data_signals(self):\n",
    "        \"\"\"\n",
    "        Get full connected segments data from all sensor from folders\n",
    "        \"\"\"\n",
    "        combine_signals = {} \n",
    "        for patient in self._sorted_data:\n",
    "            for sensor in patient:\n",
    "                signal_combined_list =[]\n",
    "                \n",
    "                for signal in sensor:\n",
    "                    dfs=[]\n",
    "                    key_name = re.sub(\"_segment_\\d+.parquet\", \"\", signal[0])\n",
    "                    key_name = re.sub(\"/.+/.+/\", \"\", key_name)\n",
    "                    for segment in signal:\n",
    "                        df = pd.read_parquet(segment)\n",
    "\n",
    "                        # Append the dataframe to the list\n",
    "                        dfs.append(df)\n",
    "                    combined_signal = pd.concat(dfs, axis=0)\n",
    "                    print(key_name)\n",
    "                    print(combined_signal)\n",
    "                    combine_signals[key_name] = combined_signal\n",
    "        return combine_signals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb241c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EpilepsyDataset('/workspace/data_seerpy/data_seerpy/data/')\n",
    "#print(dataset._sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff4879ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_parquet(\"/workspace/data_seerpy/data_seerpy/data/MSEL_01842/Empatica-TEMP/MSEL_01842_Empatica-TEMP_TEMP_segment_100.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10cbf6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             time          data\n",
      "0    1.558209e+12  3.441002e+10\n",
      "1    1.558209e+12  3.441130e+10\n",
      "2    1.558209e+12  3.441258e+10\n",
      "3    1.558209e+12  3.441385e+10\n",
      "4    1.558209e+12  3.441514e+10\n",
      "..            ...           ...\n",
      "539  1.558209e+12  3.441594e+10\n",
      "540  1.558209e+12  3.441482e+10\n",
      "541  1.558209e+12  3.441354e+10\n",
      "542  1.558209e+12  3.441226e+10\n",
      "543  1.558209e+12  3.441098e+10\n",
      "\n",
      "[544 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2cebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
